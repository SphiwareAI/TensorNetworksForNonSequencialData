{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat ./ml-100k/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove broken symbols\n",
    "! iconv -f utf-8 -t utf-8 -c ml-100k/u.item >  ml-100k/u.item2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -3 ./ml-100k/u.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv('./ml-100k/u.user', sep='|', names='user id | age | gender | occupation | zip code'.split(' | '))\n",
    "df_user['living_area'] = df_user['zip code'].map(lambda x: x[0])\n",
    "del df_user['zip code']\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['age', 'gender', 'occupation', 'living_area']\n",
    "s_users = []\n",
    "le = LabelEncoder()\n",
    "\n",
    "users_mat = []\n",
    "for feature in features_list:\n",
    "    col = le.fit_transform(df_user[feature].values)\n",
    "    users_mat.append(col)\n",
    "    s_users.append(len(le.classes_))\n",
    "users_mat = np.array(users_mat).T\n",
    "print(users_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = {}\n",
    "for i, id in enumerate(df_user['user id'].values):\n",
    "    users[id] = users_mat[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -3 ./ml-100k/u.item2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_csv('./ml-100k/u.item2', \n",
    "                      sep='|', \n",
    "                      names=(['id', 'title', 'release_date', 'video_release_date', 'url'] + \n",
    "                             ['g{}'.format(i) for i in range(19)])\n",
    "                     )\n",
    "df_item['year'] = df_item['release_date'].map(lambda x: str(x).split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for age in list(map(str, df_item['year'].values)):\n",
    "    if age == 'nan':\n",
    "        age='1600'\n",
    "    res.append(int(round(int(age), -1)))\n",
    "df_item['decade'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['decade'] + ['g{}'.format(i) for i in range(19)]\n",
    "s_item = []\n",
    "\n",
    "items_mat = []\n",
    "for feature in features_list:\n",
    "    col = le.fit_transform(df_item[feature].values)\n",
    "    items_mat.append(col)\n",
    "    s_item.append(len(le.classes_))\n",
    "items_mat = np.array(items_mat).T\n",
    "print(items_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {}\n",
    "for i, id in enumerate(df_item['id'].values):\n",
    "    items[id] = items_mat[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -3 ./ml-100k/u.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('./ml-100k/u.data', \n",
    "                      sep='\\t', \n",
    "                      names='user id | item id | rating | timestamp'.split(' | ')\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['target'] = df_data['rating'] > 4.5\n",
    "data = df_data[['user id', 'item id']].to_numpy()\n",
    "target = df_data['target'].values\n",
    "print('Mean target: {}'.format(np.mean(target==True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to pos/neg samples\n",
    "positive_idx = np.where(target==True)[0]\n",
    "negative_idx = np.where(target!=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "pos_idx_tr, pos_idx_te = train_test_split(positive_idx, random_state=42, test_size=0.5)\n",
    "neg_idx_tr, neg_idx_te = train_test_split(negative_idx, random_state=42, train_size=len(pos_idx_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idx_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(pos_idx, neg_idx):\n",
    "    rows_user = []\n",
    "    rows_item = []\n",
    "    rows_pair = []\n",
    "    for idx in list(pos_idx) + list(neg_idx):\n",
    "        u, i = data[idx]\n",
    "        # values should be 1-based \n",
    "        rows_user.append(users[u] + 1)\n",
    "        rows_item.append(items[i] + 1)\n",
    "        # u and i already 1-based\n",
    "        rows_pair.append(data[idx])\n",
    "    X = np.hstack(map(np.array, [rows_user, rows_pair, rows_item]))\n",
    "    Y = np.zeros(len(pos_idx) + len(neg_idx))\n",
    "    Y[:len(pos_idx)] = 1\n",
    "    perm = np.random.permutation(X.shape[0])\n",
    "    return X[perm], Y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 943\n",
    "n_items = 1682\n",
    "\n",
    "\n",
    "X_tr, Y_tr = build_matrix(pos_idx_tr, neg_idx_tr)\n",
    "X_te, Y_te = build_matrix(pos_idx_te, neg_idx_te)\n",
    "\n",
    "# sizes of categorical features\n",
    "s_features = s_users + [n_users, n_items] + s_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply CP-decomposition predicyion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "J6hZaFeW_mp4",
    "outputId": "b3eefae3-42c8-41e6-99d4-227b40924998"
   },
   "outputs": [],
   "source": [
    "#### The dataset was obtained after the same preprocessing of the original MovieLens 100k dataset performed in Exponential Machines (Novikov et al. 2016)\n",
    "#### to allow for direct comparison.\n",
    "#### Code adapted from Exponential Machines (2016) Novikov et al.\n",
    "#### url:https://github.com/Bihaqo/exp-machines\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from CP_Machine import CP_Machine,simple_batcher\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "X9y-rP8c_k54",
    "outputId": "b1181378-2b9f-4e90-b0cc-4460b62c6cb5"
   },
   "outputs": [],
   "source": [
    "num_features=len(s_features)\n",
    "s_features=[7,2,21,19,943,1682,10,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = X_tr, X_te\n",
    "y_train, y_test = Y_tr, Y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Logistic Regression #####\n",
    "oh = OneHotEncoder()\n",
    "oh.fit(np.vstack((x_train, x_test))-1)\n",
    "X_tr_sp = oh.transform(x_train-1)\n",
    "X_te_sp = oh.transform(x_test-1)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_tr_sp, y_train)\n",
    "y_pred = logreg.predict_proba(X_te_sp)[:, 1]\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CP_Machine #####\n",
    "\n",
    "\n",
    "cp_rank = 30\n",
    "num_features = len(s_features)\n",
    "w_cores = [None] * num_features\n",
    "begin_feature = [0] + list(np.cumsum(s_features)) #### where each feature begins in the big d vector\n",
    "\n",
    "coef = logreg.coef_[0]\n",
    "intercept = logreg.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_features):\n",
    "    local_dim = s_features[i]\n",
    " \n",
    "    tmp = np.zeros((local_dim+1,cp_rank))\n",
    "    tmp[0,:num_features]=1\n",
    "    tmp[0,i]=intercept/num_features   \n",
    "    tmp[1:s_features[i]+1,i]= coef[begin_feature[i]:begin_feature[i]+s_features[i]]\n",
    "\n",
    "    w_cores[i] = tmp.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_hist=[]\n",
    "\n",
    "#### init_std=0.001, rank=30, reg=0.00005, expreg=3.6,  auc=0.7863\n",
    "\n",
    "model = CP_Machine(rank=cp_rank, s_features=s_features, init_std=0.001, reg=0.00005, exp_reg=3.6)\n",
    "model.init_from_cores(w_cores)\n",
    "model.build_graph()\n",
    "model.initialize_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "for epoch in range(20):\n",
    "    loss_hist = []\n",
    "    penalty_hist = []\n",
    "    for x, y in simple_batcher(x_train, y_train, 256):\n",
    "        fd = {model.X: x, model.Y: 2*y-1}\n",
    "        run_ops = [model.trainer, model.outputs, model.loss, model.penalty, model.G]\n",
    "\n",
    "        _, outs, batch_loss, penalty,weights = model.session.run(run_ops, fd)\n",
    "\n",
    "        loss_hist.append(batch_loss)\n",
    "        penalty_hist.append(penalty)\n",
    "    epoch_train_loss = np.mean(loss_hist)\n",
    "    epoch_train_pen = np.mean(penalty_hist)\n",
    "    \n",
    "#    epoch_stats = {'epoch': epoch,'train_logloss': float(epoch_train_loss)}\n",
    "    epoch_stats = {'train_MSE': float(epoch_train_loss)}\n",
    "\n",
    "     # test phase\n",
    "#    if epoch%1==0 and epoch>0:\n",
    "    fd = {model.X: x_test, model.Y: 2*y_test-1}\n",
    "    run_ops = [model.outputs, model.loss, model.penalty, model.penalized_loss]\n",
    "\n",
    "    outs, raw_loss, raw_penalty, loss = model.session.run(run_ops, fd)\n",
    "    epoch_test_loss = roc_auc_score(y_test, outs)\n",
    "    epoch_stats['test_auc'] = float(epoch_test_loss),\n",
    "    #epoch_stats['penalty'] = float(raw_penalty)\n",
    "    print('{}: te_auc: {:.4f}'.format(epoch, epoch_test_loss))\n",
    "\n",
    "    epoch_hist.append(epoch_stats)\n",
    "end=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(epoch_hist).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print('Training Time:{}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nM8zLc6UygwN"
   },
   "source": [
    "# Apply Exponetial Machines model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TFExpMachine import TFExpMachine, simple_batcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate the W tensor cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rank = 10\n",
    "\n",
    "num_features = len(s_features)\n",
    "w_cores = [None] * num_features\n",
    "\n",
    "coef = logreg.coef_[0]\n",
    "intercept = logreg.intercept_[0]\n",
    "\n",
    "# see paper for details about initialization\n",
    "begin_feature = [0] + list(np.cumsum(s_features))\n",
    "for i in range(num_features):\n",
    "    n_factors = s_features[i]\n",
    "    if i == 0:\n",
    "        tmp = np.zeros((n_factors+1, 1, target_rank))\n",
    "        for local_j, global_j in enumerate([-1] + list(range(begin_feature[i], s_features[i]))):\n",
    "            if local_j==0:\n",
    "                tmp[local_j,:1,:2] = [1, 0]\n",
    "            else:\n",
    "                tmp[local_j,:1,:2] = [0, coef[global_j]]\n",
    "        w_cores[i] = tmp.astype(np.float32)\n",
    "            \n",
    "    elif i == num_features-1:\n",
    "        tmp = np.zeros((n_factors+1, target_rank, 1))\n",
    "        for local_j, global_j in enumerate([-1] + list(range(begin_feature[i], s_features[i]))):\n",
    "            if local_j==0:\n",
    "                tmp[local_j,:2,:1] = np.array([[intercept], [1]])\n",
    "            else:\n",
    "                tmp[local_j,:2,:1] = [[coef[global_j]], [0]]\n",
    "        w_cores[i] = tmp.astype(np.float32)\n",
    "            \n",
    "    else:\n",
    "        tmp = np.zeros((n_factors+1, target_rank, target_rank))\n",
    "        for local_j, global_j in enumerate([-1] + list(range(begin_feature[i], s_features[i]))):\n",
    "            if local_j==0:\n",
    "                tmp[local_j,:2,:2] = np.eye(2)\n",
    "            else:\n",
    "                tmp[local_j,:2,:2] = [[0, coef[global_j]], [0,0]]\n",
    "        w_cores[i] = tmp.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.destroy()\n",
    "model = TFExpMachine(rank=target_rank, s_features=s_features, init_std=0.001, reg=0.012, exp_reg=1.8)\n",
    "model.init_from_cores(w_cores)\n",
    "model.build_graph()\n",
    "model.initialize_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_hist = []\n",
    "for epoch in range(50):\n",
    "    # train phase\n",
    "    loss_hist = []\n",
    "    penalty_hist = []\n",
    "    for x, y in simple_batcher(x_train, y_train, 256):\n",
    "        fd = {model.X: x, model.Y: 2*y-1}\n",
    "        run_ops = [model.trainer, model.outputs, model.loss, model.penalty]\n",
    "        _, outs, batch_loss, penalty = model.session.run(run_ops, fd)\n",
    "        loss_hist.append(batch_loss)\n",
    "        penalty_hist.append(penalty)\n",
    "    epoch_train_loss = np.mean(loss_hist)\n",
    "    epoch_train_pen = np.mean(penalty_hist)\n",
    "    \n",
    "    epoch_stats = {\n",
    "        'epoch': epoch,\n",
    "        'train_logloss': float(epoch_train_loss)\n",
    "    }\n",
    "    \n",
    "    # test phase\n",
    "    if epoch%2==0 and epoch>0:\n",
    "        fd = {model.X: x_test, model.Y: 2*y_test-1}\n",
    "        run_ops = [model.outputs, model.loss, model.penalty, model.penalized_loss]\n",
    "        outs, raw_loss, raw_penalty, loss = model.session.run(run_ops, fd)\n",
    "        epoch_test_loss = roc_auc_score(y_test, outs)\n",
    "        epoch_stats['test_auc'] = float(epoch_test_loss),\n",
    "        epoch_stats['penalty'] = float(raw_penalty)\n",
    "        print('{}: te_auc: {:.4f}'.format(epoch, epoch_test_loss))\n",
    "    epoch_hist.append(epoch_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot([x['epoch'] for x in epoch_hist if 'test_auc' in x], [x['test_auc'] for x in epoch_hist if 'test_auc' in x])\n",
    "grid()\n",
    "ylim(0.775, 0.785)\n",
    "xlabel('epoch')\n",
    "ylabel('test auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MovieLens.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
